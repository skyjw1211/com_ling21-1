{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd013ae15b2b65dbdeeefd88d10d912a2830bdcc0ccf77ec2cf2099771942fa920d",
   "display_name": "Python 3.8.5 64-bit (conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rule_apply: 함수 외부에서 조건 검사, 함수 내에서 suffix 변환 진행\n",
    "def rule_apply(token, suffix1, suffix2): #suffix1이 충족하면, suffix2로 치환\n",
    "    res = token\n",
    "    if len(token) > len(suffix1) and token[-len(suffix1):].lower() == suffix1:\n",
    "        res = token[:-len(suffix1)] + suffix2\n",
    "    return res\n",
    "\n",
    "def temp_stemming(token, suffix1):\n",
    "    res = token\n",
    "\n",
    "    if len(token) > len(suffix1) and token[-len(suffix1):].lower() == suffix1:\n",
    "        return token[:-len(suffix1)]\n",
    "    \n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_m: m의 개수를 센다, m의 개수 리턴, stem을 input으로\n",
    "#stem에서 VC 발견하면 cnt+1, stem돌면서 현재 state(v인지)\n",
    "\n",
    "## 모든 문자열은 알파벳임을 전제, \n",
    "#현재 상태 v > not v 만남 = m+1, state= not v\n",
    "#현재 상태 v > v 만남 = 다음 진행\n",
    "#현재 상태 not v > v 만남 = state = v\n",
    "#현재 상태 not v > not v 만남 = 다음 진행\n",
    "\n",
    "vowels = ['a', 'e', 'i', 'o', 'u', 'A', 'E', 'I', 'O', 'U']\n",
    "def count_m(temp_stem):\n",
    "    is_state_v = 0\n",
    "    m = 0\n",
    "\n",
    "    for ch in temp_stem:\n",
    "        if is_state_v == 1 and ch not in vowels:\n",
    "            m += 1\n",
    "            is_state_v = 0\n",
    "        elif is_state_v == 1 and ch in vowels:\n",
    "            continue\n",
    "        elif is_state_v == 0 and ch in vowels:\n",
    "            is_state_v = 1\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "    return m\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# condition *S: if len(temp_stem) >= 1 and temp_stem[-1] in ['s', 'S']:\n",
    "# condition *v*: if set(temp_stem).intersection(vowels):\n",
    "# condition *d: if len(temp_stem) >= 2 and temp_stem[-1] == temp_stem[-2]:\n",
    "# condition *o: if len(temp_stem) >= 3 and temp_stem[-3] not in vowels and temp_stem[-2] in vowels and temp_stem[-1] not in vowels and temp_stem[-1] not in ['W', 'w', 'X', 'x', 'y', 'Y']:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step_1a:\n",
    "def step_1a(token):\n",
    "    global vowels\n",
    "    stemmed = token #stemming이 적용되지 않으면 원래 토큰 리턴\n",
    "\n",
    "    #가장 긴 조건을 먼저 검사 함으로써 logest match 가 진행되도록 한다.\n",
    "    if temp_stemming(token, 'sses') != token:\n",
    "        stemmed = rule_apply(token, 'sses', 'ss')\n",
    "\n",
    "    elif temp_stemming(token, 'ies') != token:\n",
    "        stemmed = rule_apply(token, 'ies', 'i')\n",
    "\n",
    "    elif temp_stemming(token, 'ss') != token:\n",
    "        stemmed = rule_apply(token, 'ss', 'ss')\n",
    "    \n",
    "    elif temp_stemming(token, 's') != token:\n",
    "        stemmed = rule_apply(token, 's', '')\n",
    "\n",
    "    return stemmed\n",
    "\n",
    "\n",
    "#step_1b:\n",
    "def step_1b(token):\n",
    "    global vowels\n",
    "    stemmed = token #stemming이 적용되지 않으면 원래 토큰 리턴\n",
    "    \n",
    "    #1b-1\n",
    "    if temp_stemming(token, 'eed') != token:\n",
    "        if count_m(temp_stemming(token, 'eed')) > 0:\n",
    "            stemmed = rule_apply(token, 'eed', 'ee')\n",
    "    elif temp_stemming(token, 'ed') != token:\n",
    "        if set(temp_stemming(token, 'ed')).intersection(vowels):\n",
    "            stemmed = rule_apply(token, 'ed', '')\n",
    "\n",
    "    elif temp_stemming(token, 'ing') != token: \n",
    "        if set(temp_stemming(token, 'ing')).intersection(vowels):\n",
    "            stemmed = rule_apply(token, 'ing', '')\n",
    "\n",
    "    if stemmed != token: #1b-1에서 stemming이 일어난 token에 대해서만\n",
    "        \n",
    "    #1b-2\n",
    "        if temp_stemming(stemmed, 'at') != stemmed:\n",
    "            stemmed = rule_apply(stemmed, 'at', 'ate')\n",
    "\n",
    "        elif temp_stemming(stemmed, 'bl') != stemmed:\n",
    "            stemmed = rule_apply(stemmed, 'bl', 'ble')\n",
    "\n",
    "        elif temp_stemming(stemmed, 'iz') != stemmed:\n",
    "            stemmed = rule_apply(stemmed, 'iz', 'ize')\n",
    "\n",
    "        elif len(stemmed) >= 2 and stemmed[-1] == stemmed[-2] and stemmed[-1] not in vowels and stemmed[-1] not in ['L', 'l', 'S', 's', 'Z', 'z']:\n",
    "            stemmed = stemmed[:-1]\n",
    "        \n",
    "        elif count_m(stemmed) == 1 and len(stemmed) >= 3 and stemmed[-3] not in vowels and stemmed[-2] in vowels and stemmed[-1] not in vowels and stemmed[-1] not in ['W', 'w', 'X', 'x', 'y', 'Y']:\n",
    "            stemmed = stemmed +'e'\n",
    "\n",
    "    return stemmed\n",
    "\n",
    "\n",
    "#step_1c()\n",
    "def step_1c(token):\n",
    "    global vowels\n",
    "    stemmed = token\n",
    "\n",
    "    if temp_stemming(token, 'y') != token and set(temp_stemming(token, 'ed')).intersection(vowels):\n",
    "        stemmed = rule_apply(token, 'y', 'i')\n",
    "    return stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step_2()\n",
    "def step_2(token):\n",
    "    global vowels\n",
    "    stemmed = token\n",
    "\n",
    "    if temp_stemming(token, 'ational') != token :\n",
    "        if count_m(temp_stemming(token, 'ational')) > 0:\n",
    "            stemmed = rule_apply(token, 'ational', 'ate')\n",
    "\n",
    "    elif temp_stemming(token, 'tional') != token:\n",
    "        if count_m(temp_stemming(token, 'tional')) > 0:\n",
    "            stemmed = rule_apply(token, 'tional', 'tion')\n",
    "    \n",
    "    elif temp_stemming(token, 'enci') != token :\n",
    "        if count_m(temp_stemming(token, 'enci')) > 0:\n",
    "            stemmed = rule_apply(token, 'enci', 'ence')\n",
    "\n",
    "    elif temp_stemming(token, 'anci') != token :\n",
    "        if count_m(temp_stemming(token, 'anci')) > 0:\n",
    "            stemmed = rule_apply(token, 'anci', 'ance')\n",
    "\n",
    "    elif temp_stemming(token, 'izer') != token: \n",
    "        if count_m(temp_stemming(token, 'izer')) > 0:\n",
    "            stemmed = rule_apply(token, 'izer', 'ize')\n",
    "\n",
    "    elif temp_stemming(token, 'abli') != token: \n",
    "        if count_m(temp_stemming(token, 'abli')) > 0:\n",
    "            stemmed = rule_apply(token, 'abli', 'able')\n",
    "\n",
    "    elif temp_stemming(token, 'alli') != token: \n",
    "        if count_m(temp_stemming(token, 'alli')) > 0:\n",
    "            stemmed = rule_apply(token, 'alli', 'al')\n",
    "\n",
    "    elif temp_stemming(token, 'entli') != token: \n",
    "        if count_m(temp_stemming(token, 'entli')) > 0:\n",
    "            stemmed = rule_apply(token, 'entli', 'ent')\n",
    "\n",
    "    elif temp_stemming(token, 'eli') != token: \n",
    "        if count_m(temp_stemming(token, 'eli')) > 0:\n",
    "            stemmed = rule_apply(token, 'eli', 'e')\n",
    "\n",
    "    elif temp_stemming(token, 'ousli') != token: \n",
    "        if count_m(temp_stemming(token, 'ousli')) > 0:\n",
    "            stemmed = rule_apply(token, 'ousli', 'ous')\n",
    "\n",
    "    elif temp_stemming(token, 'ization') != token: \n",
    "        if count_m(temp_stemming(token, 'ization')) > 0:\n",
    "            stemmed = rule_apply(token, 'ization', 'ize')\n",
    "\n",
    "    elif temp_stemming(token, 'ation') != token: \n",
    "        if count_m(temp_stemming(token, 'ation')) > 0:\n",
    "            stemmed = rule_apply(token, 'ation', 'ate')\n",
    "\n",
    "    elif temp_stemming(token, 'ator') != token:  \n",
    "        if count_m(temp_stemming(token, 'ator')) > 0:\n",
    "            stemmed = rule_apply(token, 'ator', 'ate')\n",
    "    \n",
    "    elif temp_stemming(token, 'alism') != token: \n",
    "        if count_m(temp_stemming(token, 'alism')) > 0:\n",
    "            stemmed = rule_apply(token, 'alism', 'al')\n",
    "\n",
    "    elif temp_stemming(token, 'iveness') != token: \n",
    "        if count_m(temp_stemming(token, 'iveness')) > 0:\n",
    "            stemmed = rule_apply(token, 'iveness', 'ive')\n",
    "\n",
    "    elif temp_stemming(token, 'fulness') != token: \n",
    "        if count_m(temp_stemming(token, 'fulness')) > 0:\n",
    "            stemmed = rule_apply(token, 'fulness', 'ful')\n",
    "\n",
    "    elif temp_stemming(token, 'ousness') != token: \n",
    "        if count_m(temp_stemming(token, 'ousness')) > 0:\n",
    "            stemmed = rule_apply(token, 'ousness', 'ous')\n",
    "\n",
    "    elif temp_stemming(token, 'aliti') != token: \n",
    "        if count_m(temp_stemming(token, 'aliti')) > 0:\n",
    "            stemmed = rule_apply(token, 'aliti', 'al')\n",
    "\n",
    "    elif temp_stemming(token, 'iviti') != token: \n",
    "        if count_m(temp_stemming(token, 'iviti')) > 0:\n",
    "            stemmed = rule_apply(token, 'iviti', 'ive')\n",
    "\n",
    "    elif temp_stemming(token, 'biliti') != token: \n",
    "        if count_m(temp_stemming(token, 'biliti')) > 0:\n",
    "            stemmed = rule_apply(token, 'biliti', 'ble')\n",
    "\n",
    "    return stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step3\n",
    "\n",
    "def step_3(token):\n",
    "    global vowels\n",
    "    stemmed = token\n",
    "\n",
    "    if temp_stemming(token, 'icate') != token: \n",
    "        if count_m(temp_stemming(token, 'icate')) > 0:\n",
    "            stemmed = rule_apply(token, 'icate', 'ic')\n",
    "    \n",
    "    elif temp_stemming(token, 'ative') != token: \n",
    "        if count_m(temp_stemming(token, 'ative')) > 0:\n",
    "            stemmed = rule_apply(token, 'ative', '')\n",
    "\n",
    "    elif temp_stemming(token, 'alize') != token: \n",
    "        if count_m(temp_stemming(token, 'alize')) > 0:\n",
    "            stemmed = rule_apply(token, 'alize', 'al')\n",
    "\n",
    "    elif temp_stemming(token, 'iciti') != token: \n",
    "        if count_m(temp_stemming(token, 'iciti')) > 0:\n",
    "            stemmed = rule_apply(token, 'iciti', 'ic')\n",
    "\n",
    "    elif temp_stemming(token, 'ful') != token: \n",
    "        if count_m(temp_stemming(token, 'ful')) > 0:\n",
    "            stemmed = rule_apply(token, 'ful', '')\n",
    "\n",
    "    elif temp_stemming(token, 'ness') != token: \n",
    "        if count_m(temp_stemming(token, 'ness')) > 0:\n",
    "            stemmed = rule_apply(token, 'ness', '')\n",
    "\n",
    "    return stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step4\n",
    "\n",
    "def step_4(token):\n",
    "    global vowels\n",
    "    stemmed = token\n",
    "\n",
    "    if temp_stemming(token, 'al') != token: \n",
    "        if count_m(temp_stemming(token, 'al')) > 1:\n",
    "            stemmed = rule_apply(token, 'al', '')\n",
    "    \n",
    "    elif temp_stemming(token, 'ance') != token: \n",
    "        if count_m(temp_stemming(token, 'ance')) > 1:\n",
    "            stemmed = rule_apply(token, 'ance', '')\n",
    "\n",
    "    elif temp_stemming(token, 'ence') != token: \n",
    "        if count_m(temp_stemming(token, 'ence')) > 1:\n",
    "            stemmed = rule_apply(token, 'ence', '')\n",
    "\n",
    "    elif temp_stemming(token, 'er') != token: \n",
    "        if count_m(temp_stemming(token, 'er')) > 1:\n",
    "            stemmed = rule_apply(token, 'er', '')\n",
    "\n",
    "    elif temp_stemming(token, 'ic') != token: \n",
    "        if count_m(temp_stemming(token, 'ic')) > 1:\n",
    "            stemmed = rule_apply(token, 'ic', '')\n",
    "\n",
    "    elif temp_stemming(token, 'able') != token: \n",
    "        if count_m(temp_stemming(token, 'able')) > 1:\n",
    "            stemmed = rule_apply(token, 'able', '')\n",
    "\n",
    "    elif temp_stemming(token, 'ible') != token: \n",
    "        if count_m(temp_stemming(token, 'ible')) > 1:\n",
    "            stemmed = rule_apply(token, 'ible', '')\n",
    "\n",
    "    elif temp_stemming(token, 'ant') != token: \n",
    "        if count_m(temp_stemming(token, 'ant')) > 1:\n",
    "            stemmed = rule_apply(token, 'ant', '')\n",
    "\n",
    "    elif temp_stemming(token, 'ement') != token: \n",
    "        if count_m(temp_stemming(token, 'ement')) > 1:\n",
    "            stemmed = rule_apply(token, 'ement', '')\n",
    "\n",
    "    elif temp_stemming(token, 'ment') != token:\n",
    "        if count_m(temp_stemming(token, 'ment')) > 1:\n",
    "            stemmed = rule_apply(token, 'ment', '')\n",
    "\n",
    "    elif temp_stemming(token, 'ent') != token: \n",
    "        if count_m(temp_stemming(token, 'ent')) > 1:\n",
    "            stemmed = rule_apply(token, 'ent', '')\n",
    "\n",
    "    elif temp_stemming(token, 'ion') != token: \n",
    "        if token[-1] in ['s', 'S', 't', 'T'] and count_m(temp_stemming(token, 'ion')) > 1:\n",
    "            stemmed = rule_apply(token, 'ion', '')\n",
    "\n",
    "    elif temp_stemming(token, 'ou') != token: \n",
    "        if count_m(temp_stemming(token, 'ou')) > 1:\n",
    "            stemmed = rule_apply(token, 'ou', '')\n",
    "\n",
    "    elif temp_stemming(token, 'ism') != token: \n",
    "        if count_m(temp_stemming(token, 'ism')) > 1:\n",
    "            stemmed = rule_apply(token, 'ism', '')\n",
    "\n",
    "    elif temp_stemming(token, 'ate') != token: \n",
    "        if count_m(temp_stemming(token, 'ate')) > 1:\n",
    "            stemmed = rule_apply(token, 'ate', '')\n",
    "\n",
    "    elif temp_stemming(token, 'iti') != token: \n",
    "        if count_m(temp_stemming(token, 'iti')) > 1:\n",
    "            stemmed = rule_apply(token, 'iti', '')\n",
    "\n",
    "    elif temp_stemming(token, 'ous') != token: \n",
    "        if count_m(temp_stemming(token, 'ous')) > 1:\n",
    "            stemmed = rule_apply(token, 'ous', '')\n",
    "\n",
    "    elif temp_stemming(token, 'ive') != token: \n",
    "        if count_m(temp_stemming(token, 'ive')) > 1:\n",
    "            stemmed = rule_apply(token, 'ive', '')\n",
    "\n",
    "    elif temp_stemming(token, 'ize') != token: \n",
    "        if count_m(temp_stemming(token, 'ize')) > 1:\n",
    "            stemmed = rule_apply(token, 'ize', '')\n",
    "\n",
    "    return stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step5\n",
    "\n",
    "def step_5(token):\n",
    "    global vowels\n",
    "    stemmed = token\n",
    "\n",
    "    #step 5a\n",
    "    if temp_stemming(token, 'e') != token :\n",
    "        if count_m(temp_stemming(token, 'e')) > 1:\n",
    "            stemmed = rule_apply(token, 'e', '')\n",
    "\n",
    "    elif temp_stemming(token, 'e') != token:\n",
    "        if count_m(temp_stemming(token, 'e')) == 1:\n",
    "            temp_stem = temp_stemming(token, 'e')\n",
    "            if len(temp_stem) >= 3 and temp_stem[-3] not in vowels and temp_stem[-2] in vowels and temp_stem[-1] not in vowels and temp_stem[-1] not in ['W', 'w', 'X', 'x', 'y', 'Y']:\n",
    "                stemmed = rule_apply(token, 'ize', '')\n",
    "\n",
    "    #step 5b\n",
    "    if count_m(token) > 1 and token[-1] in ['l', 'L'] and token[-1] == token[-2]:\n",
    "        stemmed = token[:-1]\n",
    "\n",
    "    return stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "token = 'agree'\n",
    "count_m(temp_stemming(token, 'eed')) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "caresses->caress\nponies->poni\nties->ti\ncaress->caress\ncats->cat\nfeed->feed\nagreed->agree\nplastered->plaster\nbled->bled\nmotoring->motor\nsing->sing\nconflated->conflat\ntroubled->trouble\nsized->size\nhopping->hop\ntanned->tan\nfalling->fall\nhissing->hiss\nfizzed->fizz\nfailing->fail\nfiling->file\nhappy->happi\nsky->sky\nrelational->relat\nconditional->condition\nrelational->relat\nvalency->valenc\nhesitancy->hesit\ndigitizer->digit\nconformably->conform\nradically->radic\ndifferently->differ\nvilely->vile\nanalougously->analoug\nvietnamization->vietnam\npredication->predic\noperator->oper\nfeudalism->feudal\ndecisiveness->decis\nhopehulness->hopehul\ncallousness->callous\nformality->formal\nsensitivity->sensit\nsensibility->sensibl\ntriplicate->triplic\nformative->form\nformalize->formal\nelectricity->electr\nelectrical->electric\nhopeful->hope\ngoodness->good\nrevival->reviv\nallowance->allow\ninference->infer\nairliner->airlin\ngyroscopic->gyroscop\nadjustable->adjust\ndefensible->defens\nirritant->irrit\nreplacement->replac\nadjustment->adjust\ndependent->depend\nadoption->adoption\nhomologous->homolog\ncommunism->commun\nactivate->activ\nangularity->angular\nhomogous->homog\neffective->effect\nbowdlerize->bowdler\nprobate->probat\nreplacementcease->replacementceas\ncontroll->control\nroll->roll\n"
     ]
    }
   ],
   "source": [
    "test_case = 'caresses ponies ties caress cats feed agreed plastered bled motoring  sing conflated troubled sized hopping tanned falling hissing fizzed failing filing happy sky'\n",
    "\n",
    "with open('porter_test_data.txt', 'r', encoding = 'utf8') as f:\n",
    "    data = f.read()\n",
    "test_tokens = data.split()\n",
    "\n",
    "for t in test_tokens:\n",
    "    res = ''\n",
    "\n",
    "    print(t, end = '->')\n",
    "    res = step_1a(t)\n",
    "\n",
    "    # print(res, end = '(step_1b)->')\n",
    "    res = step_1b(res)\n",
    "\n",
    "    # print(res, end = '(step_1c)->')\n",
    "    res = step_1c(res)\n",
    "\n",
    "    # print(res, end = '(step_2)->')\n",
    "    res = step_2(res)\n",
    "\n",
    "    # print(res, end = '(step_3)->')\n",
    "    res = step_3(res)\n",
    "\n",
    "    # print(res, end = '(step_4)->')\n",
    "    res = step_4(res)\n",
    "\n",
    "    # print(res, end = '(step_5)->')\n",
    "    res = step_5(res)\n",
    "\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_stem = 'abey'\n",
    "if len(temp_stem) >= 3 and temp_stem[-3] not in vowels and temp_stem[-2] in vowels and temp_stem[-1] not in vowels and temp_stem[-1] not in ['W', 'w', 'X', 'x', 'y', 'Y']:\n",
    "    print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-2"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "-len('ab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}